{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a615d28",
   "metadata": {},
   "source": [
    "# Iris Dataset Prediction using Amazon SageMaker XGBoost\n",
    "\n",
    "> The free tier resources are sufficient for this hands-on notebook.  \n",
    "> Use `ml.t3.medium` for notebooks, and `ml.m4.xlarge` for training and inference.\n",
    "\n",
    "First, we import some libraries and load the public dataset from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357fa741-65a5-43ff-964e-fc2866f22cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684be01-e378-4f69-bbf4-31876ef64bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Print the label species (setosa, versicolor, virginica)\n",
    "print(iris.target_names)\n",
    "\n",
    "# Print the names of the four features\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6728328",
   "metadata": {},
   "source": [
    "Identify the features and classification, then perform train-test split.  \n",
    "For simplicity, we do not consider the validation set for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dcc255-5eb8-490a-9764-3cc694847e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "    'sepal length': iris.data[:,0],\n",
    "    'sepal width': iris.data[:,1],\n",
    "    'petal length': iris.data[:,2],\n",
    "    'petal width': iris.data[:,3],\n",
    "    'species': iris.target\n",
    "})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeef2e2-9c74-4e8b-88eb-3665d0830761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and labels\n",
    "X = data[['sepal length', 'sepal width', 'petal length', 'petal width']]  \n",
    "y = data['species']  \n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb61a763-38b5-4eca-9dc3-a22fb8d991bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train and test csv\n",
    "train = pd.concat([pd.Series(y_train, index=X_train.index, name='species', dtype='int'), X_train], axis=1)\n",
    "test = pd.concat([pd.Series(y_test, index=X_test.index, name='species', dtype='int'), X_test], axis=1)\n",
    "\n",
    "train.to_csv('train.csv', index=False, header=False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be57c01e",
   "metadata": {},
   "source": [
    "Upload the train data to a S3 bucket and confirm that it was successful.  \n",
    "The training script/model later will read data from this S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a56e08-f1f1-407c-9eb0-4aea0afe222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3, os\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'IrisDataset'\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(\n",
    "    os.path.join(prefix, 'data/train.csv')).upload_file('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2d94b4-ec2d-47e0-9d6e-756d5070336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls {bucket}/{prefix}/data --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74afb2a2",
   "metadata": {},
   "source": [
    "You can check out details about your sagemaker session below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34112a84-a4e3-4f86-b8c4-c1cd8ed4b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(f'Aws Region name : {region}')\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "print(f'Role ARN (AWS Resource Name) : {role}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a856f9c6",
   "metadata": {},
   "source": [
    "We instantiate a built-in algorithm from SageMaker - XGBoost since our Iris dataset contains tabular data.  \n",
    "Set some parameters and send a request for training to begin.\n",
    "\n",
    "> Amazon SageMaker provides a suite of built-in algorithms, pre-trained models, and pre-built solution templates to help data scientists and machine learning practitioners get started on training and deploying machine learning models quickly.\n",
    "\n",
    "If you would like to find out more about XGBoost, you may read the article <a href=\"https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52610a73-96dd-4045-bb57-68b1b5e3c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import TrainingInput\n",
    "\n",
    "s3_output_location = 's3://{}/{}/{}'.format(bucket, prefix, 'xgboostModel')\n",
    "container = sagemaker.image_uris.retrieve('xgboost', region, 'latest')\n",
    "\n",
    "xgboostModel = sagemaker.estimator.Estimator(\n",
    "    image_uri=container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sagemaker.Session()\n",
    ")\n",
    "\n",
    "xgboostModel.set_hyperparameters(    \n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    num_round=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b147767c-c620-4215-a0c0-85296a501321",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Takes 5 minutes to train\n",
    "\n",
    "from sagemaker.session import TrainingInput\n",
    "\n",
    "training_input = TrainingInput('s3://{}/{}/{}'.format(bucket, prefix, 'data/train.csv'), content_type='csv')\n",
    "xgboostModel.fit({'train': training_input}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c587e03",
   "metadata": {},
   "source": [
    "Our model training has completed! Now we need to deploy it so that can we can inference from it and test the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac47b98-4aa8-418f-abc0-5230ecadfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes 5 minutes to deploy to endpoint\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "xgb_predictor = xgboostModel.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    serializer=CSVSerializer()\n",
    ")\n",
    "\n",
    "xgb_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5886657e",
   "metadata": {},
   "source": [
    "You can have a look at the accuracy below. Looks like our model is doing good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8982dbf0-4c63-4bb1-a571-ca89677c4b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_array = test.drop(['species'], axis=1).values \n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8')\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad139ce2-e8e3-49e6-9bc9-175c27997850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = np.fromstring(predictions[1:], sep=',')\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f01f0",
   "metadata": {},
   "source": [
    "We now proceed to create our Lambda function and API gateway for the rest of this hands-on.\n",
    "\n",
    "<br><hr><br>\n",
    "\n",
    "Do remember to clean up your resources when the workshop ends! (Uncomment the lines below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a455522-82d1-4cb6-8132-e68b0576bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "\n",
    "# bucket_to_delete = boto3.resource('s3').Bucket(bucket)\n",
    "# bucket_to_delete.objects.all().delete()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "69d49a09ba400833a2881d11b97d698fcf1d85f7e394e3cad808f38b08f54c79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
